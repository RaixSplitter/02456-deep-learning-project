{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from typing import Optional,Iterable\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms \n",
    "from torchvision.datasets import MNIST\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(target, pred):\n",
    "    return metrics.accuracy_score(target.detach().cpu().numpy(), pred.detach().cpu().numpy())\n",
    "\n",
    "def compute_confusion_matrix(target, pred, normalize=None):\n",
    "    return metrics.confusion_matrix(\n",
    "        target.detach().cpu().numpy(), \n",
    "        pred.detach().cpu().numpy(),\n",
    "        normalize=normalize\n",
    "    )\n",
    "\n",
    "def pkernel_loss(y_pred: torch.Tensor, loss: torch.nn.Module) -> torch.Tensor:\n",
    "    total_loss = 0.\n",
    "    B = y_pred.shape[0]\n",
    "    n_classes = y_pred.shape[-1]\n",
    "    for i in range(n_classes):\n",
    "        y_target = torch.zeros_like(y_pred).scatter(1, torch.tensor([i], dtype=torch.long, device=y_pred.device).repeat(B).unsqueeze(1), 1)\n",
    "        total_loss += loss(y_pred.float(), y_target)\n",
    "    total_loss = total_loss / n_classes**0.5\n",
    "    return total_loss\n",
    "\n",
    "def get_gradient(model: torch.nn.Module, x: torch.Tensor, loss_fn: callable, opt: torch.optim.Optimizer, flatten: bool = False, use_label: bool = False, y: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Get the gradient of each element of the batch in x of the model with respect to the loss function\n",
    "    \n",
    "    Args:\n",
    "        model: the model to use\n",
    "        x: the input data [N_samples, ...]\n",
    "        y: the target data [N_samples, ...]\n",
    "        loss_fn: the loss function to use\n",
    "        opt: the optimizer to use\n",
    "        positive: whether to perturb the loss function positively or negatively\n",
    "        kernel: What type of kernel to use, can either be pKernel, direct or average\n",
    "        \n",
    "    Returns:\n",
    "        grads: the gradients of the model with respect to the loss function\n",
    "    \"\"\"\n",
    "    B = len(x)\n",
    "    device = next(model.parameters()).device\n",
    "    x = x.to(device)\n",
    "    if y is not None:\n",
    "        y = y.to(device).float()\n",
    "    opt.zero_grad()\n",
    "    y_pred = model(x)\n",
    "    if use_label:\n",
    "        y_target = y\n",
    "    else:\n",
    "        y_target = y_pred.detach().argmax(1)\n",
    "        y_target = torch.zeros_like(y_pred).scatter(1, y_target.unsqueeze(1), 1)\n",
    "       \n",
    "    loss = pkernel_loss(y_pred, loss_fn)\n",
    "    print(loss.shape)\n",
    "    # Trick to get gradient with respect to each sample in parallel\n",
    "    grads = torch.autograd.grad(loss, model.parameters(), is_grads_batched=True, grad_outputs=torch.eye(B).to(device))\n",
    "    if flatten:\n",
    "        grads = torch.cat([grad.view((B, -1)) for grad in grads], -1)\n",
    "    return grads\n",
    "\n",
    "class own_linear_layer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(own_linear_layer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.beta = 0.1\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        # Initialize the weights to normal distribution\n",
    "        nn.init.normal_(self.weight, mean=0.0, std=1.0)\n",
    "        if self.bias is not None:\n",
    "            nn.init.normal_(self.bias, mean=0.0, std=1.0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x @ self.weight.t()/(self.weight.shape[-1]**0.5) + self.beta*self.bias\n",
    "\n",
    "class SingleLayerMLP(nn.Module):\n",
    "    \"\"\" A simple single hidden-layer perceptron for MNIST classification \"\"\"\n",
    "    def __init__(self, input_size: int, output_size: int, hidden_size: int, num_layers: int = 1):\n",
    "        super(SingleLayerMLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Define layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(own_linear_layer(input_size, hidden_size))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.layers.append(own_linear_layer(hidden_size, hidden_size))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        self.layers.append(own_linear_layer(hidden_size, output_size))\n",
    "        \n",
    "        # Initialize weights\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, own_linear_layer):\n",
    "                layer.reset_parameters()\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Flatten input\n",
    "        x = x.view(-1, self.input_size)\n",
    "        \n",
    "        # Forward pass\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return [layer.weight for layer in self.layers if isinstance(layer, own_linear_layer)]\n",
    "    \n",
    "    def get_biases(self):\n",
    "        return [layer.bias for layer in self.layers if isinstance(layer, own_linear_layer)]\n",
    "    \n",
    "    def set_weights(self, weights, biases, initial_gain):\n",
    "        i = 0\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, own_linear_layer):\n",
    "                weight = weights[i]\n",
    "                bias = biases[i]\n",
    "                in_features = layer.in_features\n",
    "                out_features = layer.out_features\n",
    "                k_factor = initial_gain\n",
    "                layer.weight.data = weight.data[:out_features, :in_features]*k_factor\n",
    "                layer.bias.data = bias.data[:out_features]*k_factor\n",
    "                i += 1\n",
    "    \n",
    "\n",
    "class GaussianFit(torch.nn.Module):\n",
    "    def __init__(self, model: torch.nn.Module, device: torch.device, kernel_method: str = \"direct\", noise_var: float = 0.0):\n",
    "        super(GaussianFit, self).__init__()\n",
    "        self.device = device\n",
    "        self.model = model\n",
    "        self.kernel_method = kernel_method\n",
    "        self.noise_var = noise_var\n",
    "        self.covariance_matrix = None\n",
    "        self.optimizer = None\n",
    "        \n",
    "    def fit(self, data: Iterable[torch.Tensor], optimizer: torch.optim.Optimizer, loss_batched: torch.nn.Module):\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss_batched\n",
    "        xs, ys, y_hats = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in data:\n",
    "                xs.append(x)\n",
    "                ys.append(y)\n",
    "                y_hats.append(self.model(x.to(self.device)))\n",
    "        xs    = torch.cat(xs, 0).to(self.device)\n",
    "        y     = torch.cat(ys, 0).to(self.device)\n",
    "        y_hat = torch.cat(y_hats, 0).to(self.device)\n",
    "        self.label_diff = y - y_hat\n",
    "        self.grads = get_gradient(self.model, xs, loss_batched, self.optimizer, True, True, y=y)\n",
    "        self.update_w()\n",
    "        \n",
    "    def update_noise(self, noise_var: float):\n",
    "        self.noise_var = noise_var\n",
    "        self.update_w()\n",
    "        \n",
    "    def update_w(self):\n",
    "        self.covarinace_kernel = self.grads@self.grads.T\n",
    "        self.covariance_matrix = self.covarinace_kernel.clone()\n",
    "        self.covariance_matrix[range(self.covariance_matrix.shape[0]), range(self.covariance_matrix.shape[0])] += self.noise_var\n",
    "        self.W = torch.linalg.solve(self.covariance_matrix.cpu(), self.label_diff.cpu()).to(self.device)\n",
    "        \n",
    "    def encode_x(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Function transforming input x into the gradient kernel space \"\"\"\n",
    "        x_grad = get_gradient(self.model, x, self.loss, self.optimizer, True, True)\n",
    "        return x_grad @ self.grads.T\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_grad = get_gradient(self.model, x, self.loss, self.optimizer, True, True)\n",
    "        K_xX = x_grad@self.grads.T\n",
    "        with torch.no_grad():\n",
    "            y_hat = self.model(x)\n",
    "        return y_hat + K_xX @ self.W\n",
    " \n",
    "def MSELoss_batch(y_hat, y):\n",
    "    return 0.5*(y_hat-y).pow(2).sum(-1)\n",
    "\n",
    "\n",
    "def decision_boundary(x: torch.Tensor, threshold: float, flip_chance: float = 0) -> torch.Tensor:\n",
    "    y = ((x[:, 0] > threshold) | (x[:, 1] > threshold)).float()\n",
    "    should_flip = torch.rand(y.size()) < flip_chance\n",
    "    y[should_flip] = 1 - y[should_flip]\n",
    "    return y\n",
    "\n",
    "\n",
    "def sample_data(n: int, threshold: float = 0.5**0.5, seed: Optional[int] = None, flip_chance: float = 0) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    x = torch.rand(n, 2)\n",
    "    y = decision_boundary(x, threshold, flip_chance)\n",
    "    return x, y\n",
    "\n",
    "def plot_decision_boundary(model: torch.nn.Module, data, fig, ax, title = None) -> None:\n",
    "    x_train   = data[\"x_train\"]\n",
    "    y_train   = data[\"y_train\"]\n",
    "    x_test    = data[\"x_test\"]\n",
    "    x_grid    = data[\"x_grid\"]\n",
    "    N_testing = data[\"N_testing\"]\n",
    "    threshold = data[\"threshold\"]\n",
    "    \n",
    "    model.eval()\n",
    "    y_hat = torch.stack([model.forward(x_test_batch) for x_test_batch in torch.split(x_test, 100)]).view(-1)\n",
    "    y_acc = (y_hat >= 0.5)== ((x_test[:, 0] > threshold) | (x_test[:, 1] > threshold))\n",
    "    ax.clear()\n",
    "    \n",
    "    y_hat_reshape = y_hat.view(int(N_testing**0.5), int(N_testing**0.5)).detach().numpy().reshape(int(N_testing**0.5), int(N_testing**0.5))\n",
    "    # Plot decision boundary\n",
    "    # Color blue if y_hat > 0.5, red if y_hat < 0.5 by making a colormap of two colors\n",
    "    colors = [\"tab:red\", \"tab:blue\"]\n",
    "    custom_cmap = plt.cm.colors.ListedColormap(colors)\n",
    "    ax.contourf(*x_grid, y_hat_reshape >0.5, alpha=0.5, levels=torch.linspace(-5.5, 5.5, 3), cmap=custom_cmap)\n",
    "     \n",
    "    # Plot training data\n",
    "    ax.scatter(x_train[y_train == 0, 0], x_train[y_train == 0, 1], c='r', label='Class 0', s=4, marker='x')\n",
    "    ax.scatter(x_train[y_train == 1, 0], x_train[y_train == 1, 1], c='b', label='Class 1', s=4, marker='x')\n",
    "    # Add title\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    else:\n",
    "        ax.set_title('Accuracy: {:.2f}'.format(y_acc.float().mean().item()))\n",
    "    ax.set_xlabel('$x_0$')\n",
    "    ax.set_ylabel('$x_1$')\n",
    "    \n",
    "    # Add striped line to mark the decision boundary (x0 < threshold and x1 < threshold)\n",
    "    ax.plot([0, threshold], [threshold, threshold], 'k--')\n",
    "    ax.axvline(x=threshold, color='k', linestyle='--', ymax=threshold, label='Correct Decision boundary')\n",
    "    ax.legend(loc='upper center')\n",
    "    model.train()\n",
    "    \n",
    "def plot_NTK_decision_boundary(model, data, noise_var: float = 0.0, ax: Optional[plt.Axes] = None, fig: Optional[plt.Figure] = None, title = None):\n",
    "    n_hidden = data.get(\"n_hidden\", 64)\n",
    "    assert isinstance(n_hidden, int)\n",
    "    gradient_loader = data[\"gradient_loader\"]\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.02, momentum=0.9)\n",
    "    kernel_model = GaussianFit(model, \"cpu\", noise_var=noise_var)\n",
    "    kernel_model.fit(gradient_loader, optimizer, MSELoss_batch)\n",
    "    plot_decision_boundary(kernel_model, data, fig, ax, title)\n",
    "    plt.show()\n",
    "\n",
    "def NTK_model(model, data, noise_var: float = 0.0):\n",
    "    gradient_loader = data[\"gradient_loader\"]\n",
    "    device          = data[\"device\"]\n",
    "    optimizer    = torch.optim.SGD(model.parameters(), lr=0.02, momentum=0.9)\n",
    "    kernel_model = GaussianFit(model, device, noise_var=noise_var)\n",
    "    kernel_model.fit(gradient_loader, optimizer, MSELoss_batch)\n",
    "    \n",
    "    return kernel_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### START OF DEMO #####\n",
    "# # Setup data\n",
    "# threshold   = 0.5**0.5\n",
    "# flip_chance = 0.0\n",
    "# N_training  = 100\n",
    "# N_testing   = 10**4\n",
    "# x_train, y_train = sample_data(N_training, seed=0, flip_chance=flip_chance, threshold=threshold)\n",
    "# gradient_loader = DataLoader([(x_train[i], y_train[i, None]) for i in range(N_training)], batch_size=64, shuffle=False)\n",
    "\n",
    "# # Construct grid of sqrt(N_testing) x sqrt(N_testing) points\n",
    "# x = torch.linspace(0, 1, int(N_testing**0.5))\n",
    "# x_grid = torch.meshgrid(x, x, indexing='ij')\n",
    "# x_test = torch.stack([x_grid[0].flatten(), x_grid[1].flatten()], 1)\n",
    "# y_test = decision_boundary(x_test, threshold)\n",
    "# test_set = TensorDataset(x_test,y_test)\n",
    "# target_loader   = DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "# # Construct NN_model\n",
    "# n_in = 2\n",
    "# n_out = 1\n",
    "# n_hidden = 64*128\n",
    "# model_arch = SingleLayerMLP\n",
    "# criterion = lambda x, y: ((x-y)**2).mean()  # We need L2 loss for NTK\n",
    "# train_model = model_arch(n_in, n_out, n_hidden)\n",
    "# optimizer = torch.optim.SGD(train_model.parameters(), lr=1., momentum=0.9)\n",
    "\n",
    "# # combine into one data\n",
    "# data = {\n",
    "#     \"threshold\"       : threshold, \n",
    "#     \"flip_chance\"     : flip_chance,\n",
    "#     \"N_training\"      : N_training,\n",
    "#     \"N_testing\"       : N_testing,\n",
    "#     \"x_train\"         : x_train,\n",
    "#     \"x_test\"          : x_test,\n",
    "#     \"y_train\"         : y_train,\n",
    "#     \"y_test\"          : y_test,\n",
    "#     \"x_grid\"          : x_grid,\n",
    "#     \"n_in\"            : n_in,\n",
    "#     \"n_out\"           : n_out,\n",
    "#     \"n_hidden\"        : n_hidden,\n",
    "#     \"gradient_loader\" : gradient_loader,\n",
    "# }\n",
    "\n",
    "# # Train network to compare decision boundaries \n",
    "# train_model.train()\n",
    "# for i in tqdm(range(10000)):\n",
    "#     for x, y in gradient_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         y_hat = train_model(x)\n",
    "#         # print(y_hat.shape,y.shape)\n",
    "#         loss = ((y_hat - y.float())**2).mean()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "    \n",
    "# # Plot decision boundary\n",
    "# fig, ax = plt.subplots(2, 1)\n",
    "# fig.set_size_inches(5, 10)\n",
    "# plot_decision_boundary(train_model, data, fig, ax[0])#, 'Trained NN')\n",
    "\n",
    "# plot_NTK_decision_boundary(train_model, data, 0, ax[1], fig, 'Corresponding Gaussian Process')\n",
    "# fig.tight_layout()\n",
    "# fig.patch.set_alpha(0)  # Make background transparent\n",
    "\n",
    "# # Save figure\n",
    "# fig.savefig('decision_boundary_comparison.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate\n",
    "# valid = []\n",
    "# train_model.eval()\n",
    "# for x, y in target_loader:\n",
    "#     y_hat = train_model(x).view(-1)\n",
    "#     acc = (y_hat >= 0.5) == ((x[:, 0] > threshold) | (x[:, 1] > threshold))\n",
    "#     valid.append(acc)\n",
    "# print(torch.cat(valid).float().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "train_set = MNIST(\"../../3_Feedforward_PyTorch/temp/\", train=True, download=False, transform=transforms.ToTensor())\n",
    "test_set = MNIST(\"../../3_Feedforward_PyTorch/temp/\", train=False, download=False, transform=transforms.ToTensor())\n",
    "batch_size = 2 # both for training and testing\n",
    "\n",
    "# use only 6000 train and 1000 test\n",
    "train_loader = DataLoader([(train_set.data[i].float()/255, train_set.targets[i, None]) for i in range(3000)], batch_size=batch_size, shuffle=True,  num_workers=0, drop_last=False)\n",
    "test_loader  = DataLoader([(test_set.data[i].float()/255,  test_set.targets[i, None])  for i in range(1000)], batch_size=batch_size, shuffle=False, num_workers=0, drop_last=True)\n",
    "\n",
    "# #--- Limit for testing ---\n",
    "# train_ta = train_set.data[train_set.targets == 0][:1500].float()\n",
    "# train_tb = train_set.data[train_set.targets == 1][:1500].float()\n",
    "\n",
    "# train_la = train_set.targets[train_set.targets == 0][:1500]\n",
    "# train_lb = train_set.targets[train_set.targets == 1][:1500]\n",
    "# train_la[:] = 0\n",
    "# train_lb[:] = 1\n",
    "\n",
    "# x_train = torch.cat((train_ta,train_tb))\n",
    "# y_train = torch.cat((train_la,train_lb))\n",
    "\n",
    "# # test\n",
    "# test_ta = test_set.data[test_set.targets == 0][:500].float()\n",
    "# test_tb = test_set.data[test_set.targets == 1][:500].float()\n",
    "\n",
    "# test_la = test_set.targets[test_set.targets == 0][:500]\n",
    "# test_lb = test_set.targets[test_set.targets == 1][:500]\n",
    "# test_la[:] = 0\n",
    "# test_lb[:] = 1\n",
    "\n",
    "# x_test = torch.cat((test_ta,test_tb))\n",
    "# y_test = torch.cat((test_la,test_lb))\n",
    "\n",
    "# train_loader = DataLoader([(x_train[i].float()/255, y_train[i, None]) for i in range(3000)], batch_size=batch_size, shuffle=True, num_workers=0, drop_last=False)\n",
    "# test_loader  = DataLoader([(x_test[i].float()/255,  y_test[i, None])  for i in range(1000)], batch_size=batch_size, shuffle=False, num_workers=0, drop_last=True)\n",
    "# #--- Limit for testing ---\n",
    "\n",
    "# plot a few MNIST examples\n",
    "idx, dim, classes = 0, 28, 10\n",
    "images, labels = next(iter(train_loader))\n",
    "img = images.detach().cpu()\n",
    "\n",
    "# # create empty canvas\n",
    "# canvas = np.zeros((dim*2, 8*dim))\n",
    "\n",
    "# # fill with tensors\n",
    "# for i in range(2):\n",
    "#     for j in range(8):\n",
    "#         canvas[i*dim:(i+1)*dim, j*dim:(j+1)*dim] = img[idx].reshape((dim, dim))\n",
    "#         idx += 1\n",
    "\n",
    "# # visualize matrix of tensors as gray scale image\n",
    "# plt.figure(figsize=(4, 4))\n",
    "# plt.axis('off')\n",
    "# plt.imshow(canvas, cmap='gray')\n",
    "# plt.title('MNIST handwritten digits')\n",
    "# plt.show()\n",
    "# print(len(train_loader.dataset),len(test_loader.dataset))\n",
    "# print(images[0].size(),labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(2,8,figsize=(20,6))\n",
    "# ax = ax.flat\n",
    "# for i in range(len(ax)):\n",
    "#     ax[i].imshow(img[i], cmap=\"gray\")\n",
    "#     ax[i].set_title(labels[i].item())\n",
    "#     ax[i].axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "SingleLayerMLP(\n",
      "  (layers): ModuleList(\n",
      "    (0): own_linear_layer()\n",
      "    (1): ReLU()\n",
      "    (2): own_linear_layer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "N_training = len(train_loader.dataset)\n",
    "N_testing  = len(test_loader.dataset)\n",
    "\n",
    "# Construct NN_model\n",
    "n_in = dim**2\n",
    "n_out = classes\n",
    "n_hidden = 2**1*512 # 64*128\n",
    "model_arch = SingleLayerMLP\n",
    "criterion = lambda x, y: ((x-y)**2).mean()  # We need L2 loss for NTK\n",
    "train_model = model_arch(n_in, n_out, n_hidden, num_layers=1)\n",
    "optimizer = torch.optim.SGD(train_model.parameters(), lr=1.00, momentum=0.9)\n",
    "CELoss    = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "if torch.cuda.is_available(): device = torch.device('cuda')  \n",
    "else:                         device = torch.device('cpu')\n",
    "# device = torch.device('cpu')\n",
    "print(\"Device:\",device)\n",
    "train_model.to(device)\n",
    "print(train_model)\n",
    "\n",
    "data = {\n",
    "    \"N_training\"      : N_training,\n",
    "    \"N_testing\"       : N_testing,\n",
    "    \"n_in\"            : n_in,\n",
    "    \"n_out\"           : n_out,\n",
    "    \"n_hidden\"        : n_hidden,\n",
    "    \"gradient_loader\" : train_loader,\n",
    "    \"device\"          : device\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_every_steps = 100\n",
    "# epochs = 1\n",
    "# # Train network to compare decision boundaries \n",
    "\n",
    "# train_model.train()\n",
    "# train_acc_batches = []\n",
    "# for i in (pbar := tqdm(range(epochs))):\n",
    "#     total_loss = []\n",
    "#     for inputs, targets in train_loader:\n",
    "#         inputs, targets = inputs.to(device), targets.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         output = train_model(inputs)\n",
    "#           # loss = ((output - targets.float())**2).sum()\n",
    "#         loss = CELoss(output, targets[:,-1])\n",
    "#         print(loss)\n",
    "#         total_loss.append(round(float(loss.item),4))\n",
    "        \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         if (i+1) % validation_every_steps == 0:\n",
    "#             predictions = output.max(1)[1]\n",
    "#             train_acc_batches.append(accuracy(targets, predictions))\n",
    "        \n",
    "#     if (i+1) % validation_every_steps == 0:\n",
    "        \n",
    "#         train_acc = np.mean(train_acc_batches)\n",
    "#         train_accuracies_batches = []\n",
    "        \n",
    "#         # Compute accuracies on validation set.\n",
    "#         valid_acc_batches = []\n",
    "#         with torch.no_grad():\n",
    "#             train_model.eval()\n",
    "#             for inputs, targets in test_loader:\n",
    "#                 inputs, targets = inputs.to(device), targets.to(device)\n",
    "#                 output = train_model(inputs)\n",
    "#                 loss = ((output - targets.float())**2).mean()\n",
    "\n",
    "#                 predictions = output.max(1)[1]\n",
    "\n",
    "#                 # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=False).\n",
    "#                 valid_acc_batches.append(accuracy(targets, predictions))\n",
    "\n",
    "#             train_model.train()\n",
    "        \n",
    "#         # Append average validation accuracy to list.\n",
    "#         valid_acc = np.mean(valid_acc_batches)\n",
    "        \n",
    "#         pbar.set_description(f\"Iter: {i+1:<4}  |  train_acc: {train_acc*100:.1f}%  |  test_acc: {valid_acc*100:.1f}%   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe508d99b8449bb919a06e83d8c76a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.1\n",
      "torch.Size([3000])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 34.33 GiB. GPU 0 has a total capacity of 8.00 GiB of which 6.07 GiB is free. Of the allocated memory 776.56 MiB is allocated by PyTorch, and 81.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 49>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m NTK_valid_loss_batches \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     48\u001b[0m NTK_valid_acc_batches  \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 49\u001b[0m kernel_model \u001b[38;5;241m=\u001b[39m \u001b[43mNTK_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     51\u001b[0m     train_model\u001b[38;5;241m.\u001b[39meval()\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mNTK_model\u001b[1;34m(model, data, noise_var)\u001b[0m\n\u001b[0;32m    248\u001b[0m optimizer    \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[0;32m    249\u001b[0m kernel_model \u001b[38;5;241m=\u001b[39m GaussianFit(model, device, noise_var\u001b[38;5;241m=\u001b[39mnoise_var)\n\u001b[1;32m--> 250\u001b[0m \u001b[43mkernel_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradient_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMSELoss_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kernel_model\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mGaussianFit.fit\u001b[1;34m(self, data, optimizer, loss_batched)\u001b[0m\n\u001b[0;32m    152\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(y_hats, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_diff \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m-\u001b[39m y_hat\n\u001b[1;32m--> 154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrads \u001b[38;5;241m=\u001b[39m \u001b[43mget_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_batched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_w()\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mget_gradient\u001b[1;34m(model, x, loss_fn, opt, flatten, use_label, y)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Trick to get gradient with respect to each sample in parallel\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flatten:\n\u001b[0;32m     55\u001b[0m     grads \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([grad\u001b[38;5;241m.\u001b[39mview((B, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m grad \u001b[38;5;129;01min\u001b[39;00m grads], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\son22\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:492\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(gO):\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _engine_run_backward(\n\u001b[0;32m    483\u001b[0m             outputs,\n\u001b[0;32m    484\u001b[0m             gO,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    489\u001b[0m             accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    490\u001b[0m         )\n\u001b[1;32m--> 492\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_vmap_internals\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvjp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_none_pass_through\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m     result \u001b[38;5;241m=\u001b[39m _engine_run_backward(\n\u001b[0;32m    497\u001b[0m         outputs,\n\u001b[0;32m    498\u001b[0m         grad_outputs_,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    503\u001b[0m         accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    504\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\son22\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_vmap_internals.py:231\u001b[0m, in \u001b[0;36m_vmap.<locals>.wrapped\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    228\u001b[0m     batched_inputs, batch_size \u001b[38;5;241m=\u001b[39m _create_batched_inputs(\n\u001b[0;32m    229\u001b[0m         in_dims, args, vmap_level, func\n\u001b[0;32m    230\u001b[0m     )\n\u001b[1;32m--> 231\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_none_pass_through:\n\u001b[0;32m    233\u001b[0m         _validate_outputs(batched_outputs, func)\n",
      "File \u001b[1;32mc:\\Users\\son22\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:482\u001b[0m, in \u001b[0;36mgrad.<locals>.vjp\u001b[1;34m(gO)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(gO):\n\u001b[1;32m--> 482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgO\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\son22\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 34.33 GiB. GPU 0 has a total capacity of 8.00 GiB of which 6.07 GiB is free. Of the allocated memory 776.56 MiB is allocated by PyTorch, and 81.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "# Train network to compare decision boundaries \n",
    "\n",
    "train_model.train()\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "valid_acc  = []\n",
    "for i in (pbar := tqdm(range(epochs))):\n",
    "    train_loss_batches = []\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = train_model(inputs)\n",
    "        loss = CELoss(output, targets[:,-1])\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        predictions = output.max(1)[1]\n",
    "        train_loss_batches.append(loss.detach().cpu())\n",
    "    train_loss.append(np.mean(train_loss_batches))\n",
    "\n",
    "    # Compute accuracies on validation set.\n",
    "    valid_loss_batches = []\n",
    "    valid_acc_batches = []\n",
    "    with torch.no_grad():\n",
    "        train_model.eval()\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            output = train_model(inputs)\n",
    "            \n",
    "            loss        = CELoss(output, targets[:,-1])\n",
    "            predictions = output.max(1)[1]\n",
    "\n",
    "            # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=False).\n",
    "            valid_loss_batches.append(loss.cpu())\n",
    "            valid_acc_batches.append(accuracy(targets, predictions))\n",
    "\n",
    "        train_model.train()\n",
    "\n",
    "    valid_loss.append(np.mean(valid_loss_batches))\n",
    "    valid_acc.append(np.mean(valid_acc_batches))\n",
    "print(round(valid_acc[-1]*100,2))\n",
    "\n",
    "# NTK model\n",
    "NTK_valid_loss_batches = []\n",
    "NTK_valid_acc_batches  = []\n",
    "kernel_model = NTK_model(train_model, data)\n",
    "with torch.no_grad():\n",
    "    train_model.eval()\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        output = kernel_model(inputs)\n",
    "        \n",
    "        loss        = CELoss(output, targets[:,-1])\n",
    "        predictions = output.max(1)[1]\n",
    "        \n",
    "        NTK_valid_loss_batches.append(loss.cpu())\n",
    "        NTK_valid_acc_batches.append(accuracy(targets, predictions))\n",
    "\n",
    "print(NTK_valid_acc_batches[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000000.000000 b\n",
      "  1000000.000000 kb\n",
      "     1000.000000 mb\n",
      "        1.000000 gb\n"
     ]
    }
   ],
   "source": [
    "data_tabel = {\n",
    "    \"b\": 1,\n",
    "    \"kb\": 1000,\n",
    "    \"mb\": 1000**2,\n",
    "    \"gb\": 1000**3,\n",
    "}\n",
    "# 1 bytes = 8 bits\n",
    "\n",
    "int8 = 8\n",
    "film = 120\n",
    "min  = 60\n",
    "sek  = 60 # 1 sek = 60 frames = 60 billeder\n",
    "\n",
    "bsize = 64\n",
    "\n",
    "img = 1000**3\n",
    "# img = 1080*1920\n",
    "# img = 1080*1920 * sek #* min * film * int8 / 8 \n",
    "\n",
    "for d,v in data_tabel.items():\n",
    "    print(f\"{img/v:>16f} {d}\")\n",
    "# 28**2: 0.006 mb\n",
    "#   san: 0.620 mb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "ax[0].plot(train_loss, c=\"red\" , label=\"Train\")\n",
    "ax[0].plot(valid_loss, c=\"blue\", label=\"Valid\")\n",
    "ax[0].set_title(\"Loss\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(valid_acc)\n",
    "ax[1].set_title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 89.7%\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = np.zeros((classes, classes))\n",
    "with torch.no_grad():\n",
    "    train_model.eval()\n",
    "    test_accuracies = []\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        output = train_model(inputs)\n",
    "        loss = ((output - targets.float())**2).mean()\n",
    "\n",
    "        predictions = output.max(1)[1]\n",
    "\n",
    "        # Multiply by len(inputs) because the final batch of DataLoader may be smaller (drop_last=True).\n",
    "        test_accuracies.append(accuracy(targets, predictions))\n",
    "        \n",
    "        confusion_matrix += compute_confusion_matrix(targets, predictions)\n",
    "\n",
    "    test_accuracy = np.mean(test_accuracies)\n",
    "    \n",
    "    train_model.train()\n",
    "print(f\"Test accuracy: {test_accuracy*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def normalize(matrix, axis):\n",
    "    axis = {'true': 1, 'pred': 0}[axis]\n",
    "    return matrix / matrix.sum(axis=axis, keepdims=True)\n",
    "\n",
    "x_labels = list(range(classes))\n",
    "y_labels = x_labels\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(\n",
    "    ax=plt.gca(),\n",
    "    data=normalize(confusion_matrix, 'true'),\n",
    "    annot=True,\n",
    "    linewidths=0.5,\n",
    "    cmap=\"Reds\",\n",
    "    cbar=False,\n",
    "    fmt=\".2f\",\n",
    "    xticklabels=x_labels,\n",
    "    yticklabels=y_labels,\n",
    ")\n",
    "# plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.ylabel(\"True class\")\n",
    "plt.xlabel(\"Predicted class\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
